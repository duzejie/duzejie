[面向深度神经网络的芯片布图规划问题简介 (qq.com)](https://mp.weixin.qq.com/s/cA1AXfpV3ZcMNX9k5XKlww)

**深度神经网络的结构简介**

神经网络模仿生物神经系统建立数学模型，它由大量的网络节点（神经元）相互连接构成，一般分为三层：输入层、隐藏层和输出层。在神经网络中，关键的是节点之间的连接线，它形象刻画了节点之间的信号传递。输入信号像电流一样，沿着连接线的箭头向后方节点不断输送信息，直到从后端输出。每个连接线对应一个权重，权重的大小决定信号的重要性，这是需要神经网络从数据中不断学习得到的。网络中除了有大量的矩阵相乘线性运算（输入信号的加权求和运算）外，激活函数也起到十分重要的作用，它模拟神经元的激活，控制神经元的状态，将非线性因素引入神经网络。每个神经元有两种状态，兴奋和抑制，这两种状态由一个阈值来决定，节点被激活函数作用后的值若超过这个阈值，则该神经元将被激活，否则将处于抑制状态。

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF00BxPeXe6UTYmY5zK3dvzbSrGsD2PLxniaorbib5MxEaW9EhicCJTQgqmQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图1  神经网络示意图

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0HuS4KZOgERWWmj2paP0lyaR5PMJZteSdqMCIaoiacX5A96FTFgG4YtA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

深度学习\[1\]是神经网络的延伸，“深度”二字是指神经网络模型中隐藏层的层数超过一层。下图是一个处理手写数字“5”的卷积神经网络，其中使用了“卷积层—激活函数的ReLU层—池化层”组合（有时池化层会被省略），最后的输出层使用了“Affine-Softmax”组合。

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0ZJdswqkIJgJ6txAkFOBF5UHUPceS8blumvvvhhMazVxjGYArJLMnBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图2  基于卷积神经网络(CNN)的例子

在极具权威的ILSVRC学术竞赛中，基于深度学习的方法崭露头角，使用的网络也不断在深化，其中VGG、GoogLeNet、ResNet等是几个著名的基于CNN的网络，其深度高达数十层，甚至上百层。

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0iccWDTZ89TicZcCuYehHYZ8aLlNP0ZxFmDIBiby93t1cSVuDCuKvn05rQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图3  ILSVRC2014冠军：GoogLeNet

随着大数据和网络的大规模化，深度神经网络由于具有更多的隐藏层，我们在获取更多信息的同时，也需要进行大量的运算。根据实验表明，深度学习中大多数时间都被耗费在卷积层的乘积累加运算上；再加上为深度学习提供性能是一个端到端问题，即对一个大型数据集，系统直接学习输入和输出之间的函数映射，因此要想高速高效地进行神经网络训练，必须对系统设计进行整体优化，构建一个专用的系统。当前就有多家初创企业在探索能够使原本在通用CPU上运行的软件获得更快处理速度的定制化专用芯片。

**2**

**面向深度学习的芯片发展**

人工智能芯片\[2\]\[3\]是实现人工智能算法的硬件基础，拥有着巨大的产业价值和战略地位，在人工智能技术领域至关重要。目前人工智能领域中的机器学习、深度学习等颠覆性创新技术对芯片提出了更高的要求，在现有芯片架构的基础上，对某类特定算法进行加速，从而优化这一算法的计算速度、功耗和成本，这成为人工智能领域的关键。

人工智能芯片作为维护国家安全，提升国家竞争力的重大战略，经历了多次起伏和波折。2007年之前，由于相关产业对数据量和运算速度的要求相对较低，且人工智能芯片产业也处于探索发展时期，传统CPU芯片已经能够满足市场对计算能力的基本需求。但是随着游戏、高清视频等视听产业的快速发展，CPU有限的计算单元且计算指令遵循串行执行的方式导致芯片的效能未能得到全面发挥。此时为了有效提升芯片计算能力，具备高并行结构、多运算单元的GPU凭借其在图形数据处理和复杂算法等方面的优势而逐渐受到行业的青睐。从整体效率来看，GPU在深度学习算法的运算性能比传统CPU高出9至72倍。2010年以来云计算产业快速发展，其凭借将计算资源、储存资源、网络资源进行统一管理和分配为人工智能产业的发展搭建了简单易用的服务平台。相关研究人员可以通过云计算平台借助大量的CPU和GPU进行混合计算，极大地提高了人工智能芯片运算速度和效率。但是随着人工智能逐渐向深度学习领域发展，数据量也呈现几何级增长速度，海量的数据对芯片的计算能力也随之提出了更高的要求。2015年后，随着人工智能芯片应用场景的增多，通过改进硬件性能和芯片架构研发人工智能专用芯片成为行业重要的努力方向。

人工智能芯片目前有两个发展方向：一个是继续沿用传统的冯·诺依曼计算架构，以GPU（图形处理器）、ASIC（专用集成电路）、FPGA（现场可编程逻辑门阵列）这三种类型的芯片为代表，加速硬件计算能力；另一种是完全重新开发，颠覆传统计算架构，采用模拟人脑神经网络结构来提升计算能力。目前，国外具有代表性的人工智能芯片技术企业包括NVIDIA、Google、三星和高通等公司，国内则呈现出百家争鸣的态势，主要包括中科寒武纪、华为、灵汐科技、地平线机器人、深鉴科技、百度、平头哥等。其中寒武纪1A处理器（图4）是2016年发布的世界第一款商用深度学习专用处理器，它完全采用ASIC设计方法全定制，面积、性能功耗比等指标面向深度学习都超越了传统处理器。

![Image](https://mmbiz.qpic.cn/mmbiz_jpg/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0ibNYLuM1AqjlOE9WX6U4iawB44K3sVKKuSOPvVrZqpDWMzb63ZlkeG1Q/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

图4  寒武纪1A

**3**

**深度学习芯片的设计原理**

**3.1  深度神经网络芯片及布图规划问题介绍**

为简单描述深度芯片的设计原理，本文以Cerebras Systems公司在Supercomputing 2019上正式推出的载有Cerebras WSE\[4\]（史上最大的AI芯片）的计算产品Cerebras CS-1为例来说明。大多数深度学习的框架都支持GPU，可以高速地处理大量运算，现在CS-1不仅可以从根本上减少训练时间，而且为推理延迟设定了新的标准。对于深度神经网络，单个图像分类可以在几微秒内完成，比其他解决方案快数千倍。

WSE由633×633的计算块排列而成，每个计算块都有一个可编程的核心、48KB SRAM和一个用于与其他块互连的路由器。每个时钟周期内，计算块可以接收数据执行其处理任务，也可以将数据传输到每个相邻的计算块。除了支持传统的神经网络训练操作外，WSE还可以对整个神经网络的每一层同时进行编程和计算，这种实现全模型加速的方法是WSE独有的。

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0Cpa2eZ8PoTibeWSXFLL5wMAeEibYIuz4Gj3CBpDCoq5set0zEgqXvrUg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图5  WSE与最大的GPU性能对比

Cerebras软件平台专门为加速人工智能计算而设计，它主要包括机器学习框架、Cerebras图编译器（CGC）、高性能内核库和内核API以及支持调试和分析的开发工具。对于一个指定的深度神经网络，CGC利用XLA将TensorFlow图编译成一系列专门为给定神经网络模型生成的计算内核，并将其转化为中间表示形式。CGC将中间表示与Cerebras核库（kernel library）中的内核进行匹配，匹配结果是一个描述神经网络拓扑结构的核图（kernel graph）。然后，CGC将计算资源分配给核图中的每个内核，并将每个内核映射到芯片WSE的一个物理区域。最后，将每个网络的通信路径配置到fabric上。上述编译流程中，最关键的部分是为每个内核分配多少计算资源，即如何将描述神经网络拓扑结构的核图中的每个核映射到WSE上的二维矩形处理器模块，这类似于芯片规划中典型的布图规划(Floorplan)问题。

![Image](https://mmbiz.qpic.cn/mmbiz_jpg/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0Vn4eTpWBVhHdzeaerNAlzFqnIUkGLauRFj6S27r53ibnIewpHgbonUA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

图6  编译流程

布图规划\[5\]根据模块的面积和长宽比来优化芯片的大小、降低互连线长度并改善时延，从而确定这些模块的位置和大小。在布图规划设计中，给定![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0X2MCdEHRBYCLyiasap1hHHgYrdiaS4nY0ODkM6tthuTujJLMjFFZcffA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)个模块![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0X4efOlHzX1LzdTCdwnE70B2jDiccG8xRAaUvyWWoiagtgsbiaicfV56xkQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)及![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0X2MCdEHRBYCLyiasap1hHHgYrdiaS4nY0ODkM6tthuTujJLMjFFZcffA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)个模块的网表，其中模块可以是有固定尺寸和面积的硬模块，也可以是面积固定而长宽比在一定范围内改变的软模块。布局中较长的互连线可能会增加信号传播延迟，因此高性能的电路布局应尽可能地缩短互连线的长度。为简化布局总线长的计算，我们将核图中所有相互连接的核的中心之间的曼哈顿距离近似作为总线长。

在布图优化阶段，要求在满足某些物理设计的前提下，为每个模块选择合适的形状和位置，以使得全局边界框面积![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF03MG5V28ic47gIcvaNRnh1z8zOEs0Qk4k98VM9CXdJ8nRJPxTRR0uNxw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)和总线长![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0c13clc2q3FAiaYweJRsFm2M3bKyLF8s9AtAkxtYr383RADMvDaFsCTg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的加权和最小化。其中，一个布图规划的全局边界框是包含所有布图模块的最小轴对称矩形，总线长![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0c13clc2q3FAiaYweJRsFm2M3bKyLF8s9AtAkxtYr383RADMvDaFsCTg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的的估算如下：

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0x8vvibyeXubS2tJ55GyuDs0bJ3bQa9grdKP1pwGgu3dW2xWQwelUz2Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

上式中，![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0BDicXzzwQyaFffN2XlH3IictPLIrH4ic2HlFDVqcXmq5T0K7wlvsmgZfw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)、![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0ONicz16kfPjPubB2g2rdeVGZzCLuZZMOPgzdI0C8LIE5y2RDlTJ2ctg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)分别表示模块![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0lsDMBTXm8hXEicVDJxxuACQZtSc7s0FwSYvNzHOBkYicEP1A8ZzY323Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)与模块![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0icdUu7upf60f5XUJicNjwX2dbNzUlNLibNvAfTFcfEaXoib1wTRJKcSgqQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)之间的连接度和中心点之间的曼哈顿距离。因此，布图规划问题通常最小化

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0FfErPYibiacdp2YLvSXLnQsxUkHVE5xNHUyxpyhz4hfDYibMLo3uVq5aA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

其中，![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0IDfRareVehfmtwaJbFJXLxHYS67icahAnpeKaHt4fKAednYWWKSmRAw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1) ，![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0CsHFL5jEq7Xcg2qhqQapoy93kkwKpwHRfSK1a8YdNDq9mXLkr2E7ibg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)表示![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF03MG5V28ic47gIcvaNRnh1z8zOEs0Qk4k98VM9CXdJ8nRJPxTRR0uNxw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)和![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0c13clc2q3FAiaYweJRsFm2M3bKyLF8s9AtAkxtYr383RADMvDaFsCTg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)之间的相对重要性。

图7左边是一个中间层为三层的简单深度卷积神经网络，每一层执行一个独立的深度学习计算任务，比如卷积层(conv)进行的处理就是卷积运算。图7右边给出了它在芯片上的计算资源分配和位置布局的一个方案。需要注意的是，一个先进的深度学习网络有几十甚至是几百层，即核图是一个有着几十甚至几百个内核的有向无环图；且实际的芯片是一个由约400000个计算块排列为633×633的正方形人工智能芯片。

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0cPKvklBs7JicHAGdVjNA8XAAF8HAVYlrVbKr7PSwoqh4jggAqURqsmQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0RcMy9gicKkWRHonZN9EO78awfUXgPHVo12uicRXXMBU7VnDSpXoZ1lew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图7   一个简单神经网络及其布图方案

基于深度神经网络对人工智能芯片资源的分配和布局问题中，在WSE芯片上要进行布局的是形状大小可塑的矩形核，因此可以自由选择核的长、宽和位置。即对任一指定n层神经网络，假设其核图中的![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0X2MCdEHRBYCLyiasap1hHHgYrdiaS4nY0ODkM6tthuTujJLMjFFZcffA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)个核为![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0rbr59dvicmwa3j76MGdOot42RUFyvNpAR81FgmibcfBbO9iaTj1M0zy9A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，现为每个核![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0vvZ9JQHUUictP7SOA6hhGQoRZPho0w4kNJkgYeVVRH5NKMibVAJia0qrw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)分配矩形计算资源模块![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0tB2QnD0IMNrNh7aPAF0ljgn4QAlORibS9SQH4cqF6ia1PDObhSshR4IA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，本问题的目标是确定每个模块![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0tB2QnD0IMNrNh7aPAF0ljgn4QAlORibS9SQH4cqF6ia1PDObhSshR4IA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的高和宽，即![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0ZWILk8ic0jIrrpszgBuMndjHSaIDa04OujQ8Aqic5HOXbImH4fn8gKuQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)和![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0w8vYqZicuCMxUGvKkSNLS6ZkMONxsUYwJBuUMDTNiaIdGSibOFnqDd6Yw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，以及该矩形模块在芯片上的位置，即左下角坐标![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0vg9bRZrLpprcPbUBgFe0o1ibE4iaxicvQrHOB1NHy8OhJumHK5CdrYzVQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)。本文要介绍的基于深度学习的芯片布局问题与布图规划问题类似，但又有区别。

**3.2  基于深度神经网络芯片的布图规划问题****优****化目标**

对某一![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0X2MCdEHRBYCLyiasap1hHHgYrdiaS4nY0ODkM6tthuTujJLMjFFZcffA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)层神经网络，其核图是一个有向树![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF093s4Xia9MibZJn2WaH1W7YmF78TFVbcnsgDsicVKTicQXq1XnrIEib8utEg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，假设![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF093s4Xia9MibZJn2WaH1W7YmF78TFVbcnsgDsicVKTicQXq1XnrIEib8utEg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的有向边构成的集合为![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0gSBc9sANQN69uLP1tJ3Gc0x8VicuKbLLiaQ4ztYYfv9T7SFnfEShYJMA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，令![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0Fp2wRBFfNgM1lliaPAv1ReiajibOU1qCb2EeIicTylq3aqfMq1ueVzYk0g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)表示由核![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0lsDMBTXm8hXEicVDJxxuACQZtSc7s0FwSYvNzHOBkYicEP1A8ZzY323Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)指向核![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0icdUu7upf60f5XUJicNjwX2dbNzUlNLibNvAfTFcfEaXoib1wTRJKcSgqQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的有向边。在该核图的最终布图中，总线长为核图中所有有连线的模块中心之间的曼哈顿距离之和。令![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0Qo9BVTmRJBftpgobvtDsuEx8NibGxB9L7UkltpXtu4rtWYiaiayzbVxxg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)是其核图中![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0X2MCdEHRBYCLyiasap1hHHgYrdiaS4nY0ODkM6tthuTujJLMjFFZcffA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)个核之间的互连矩阵：

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0bxJxdCKBckwFuzq7ia3FA1IicLQPXZYo3IdJa6tVUJHY7tMrhHbia9EXA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

假设核![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0vvZ9JQHUUictP7SOA6hhGQoRZPho0w4kNJkgYeVVRH5NKMibVAJia0qrw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)对应的模块![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0tB2QnD0IMNrNh7aPAF0ljgn4QAlORibS9SQH4cqF6ia1PDObhSshR4IA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的中心坐标为![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0c4eLYIwsEVIY2XN9D8fc103Ozv4FQ2sf3Uj1BiapriaWiaia43yzh5LcicA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，核![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0hNSicicemeNtDzRz4PLUJxibVtUnVD279icxQKd1SOUQHved8icjeOJKiahg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)对应的模块![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0tOTkwLdqtMfTKBArF70HudnhByPXZDV70GBrgD6SKusMJ1j5bcDs4w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的中心坐标为![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0QN9jFVIiazoibr7hWdKaNgJgtvwLgZKDwIt33gJibyoHUDZo8CxufgL5w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，因此最小化总线长![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0VZw2PKIWtFYiaOM7dbRgbBWcbzibx0iauI2592352XApUKpUicOQgicnwrA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)表示为：

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0cx2xHWsib63wOENUkra8ppX65jSNibjlIgBTG8vhicdl9tjrYUTkbBHkA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图8所示的核库中主要有三种类型的核，conv、dblock和cblock，每种核都指定其性能函数。比如卷积核conv的性能函数conv.perf有11个参数，其中(H,W,R,S,C,K,T)是形式参数，即已知的参数，它们分别指的是输入图像的高和宽(H,W)、感受野大小(R,S)、输入和输出数据(C,K)和步幅大小![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0Ysh5FUzeh9JfBAZJv2yCTg5R5ficOjvm8U1Ag66FfNmSvryGJkrPQfg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)，这些参数作为神经网络输入的一部分，在编译过程中不发生改变。另外四个参数(h’,w’,c’,k’)是执行参数，即未知待求的参数，描述在(H,W,C,K)四个维度上分配的资源数量。执行参数决定核最终布局到WSE上的形状、执行时间和内存，需要通过编译求得。在确定执行参数后，我们易计算得到核![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0lsDMBTXm8hXEicVDJxxuACQZtSc7s0FwSYvNzHOBkYicEP1A8ZzY323Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的运行时间![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0adCPCNBpdy3AAgdaPw99IRibvx72Qg7FtAXK2WNGMpEw8tgTnl6Pk5A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)。在并行计算中运行时间最长的核决定了芯片的总体性能，因此，此问题的另一个目标是最小化核的最长执行时间，即

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0aCJVKNsrLYZE5TdibMY1UDoyibP598WMOFA4zqMOokR6DiaCeDNm5mnYw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

我们记![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0NdTYq7p0pw85vjItBJ8ObF2zvZicdEFB7dtJl7LrODHR9xcQyLa1lRA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)。

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0KQVVYh1Tb50aQfIOnaTTD41bUf7yn1GcAWKAeEiaLZjYcBoKESyykGw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

图8  核库kernel library

最后一个影响芯片加速性能的因素是适配器损失值（adapter cost）。通俗地讲，就是判断核图中相邻两核之间的执行参数是否相同，若不相同，则adapter cost加1。之所以考虑适配器损失值，是因为执行参数决定核的高度，当相邻核被分配的计算资源是有相同的高度的矩形模块时，可以实现信息传输更加高效。最终我们要得到一个指定神经网络消耗的适配器总个数，adapter cost越小，加速器性能越好。在这里分两种情况：

（1）若核图中全是卷积核conv，则比较相邻核之间的执行参数h’,w’, c’是否相同。

（2）若核图中是核dblock和cblock的混合，则比较前一个核的参数h’,w’,c3’与后一个核的参数h’,w’,c1’是否相同。

对于任意指定神经网络模型，要对芯片WSE进行计算资源的分配和布局，使得有效缩短该人工智能神经网络训练模型的时间。我们使用Python进行编程，benchmark来自ISPD 2020 Contest: Wafer-Scale Deep Learning Accelerator Placement。每个benchmark基准示例为上面三个主要优化目标指定不同的权重，即最长核执行时间![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0mx1tRu3xtCpENuP8yOPc1ocY2G3qHUpKSwfibnWbqosoPhqBQlFpw6g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)、总线长![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0VZw2PKIWtFYiaOM7dbRgbBWcbzibx0iauI2592352XApUKpUicOQgicnwrA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)和adapter cost在不同的benchmark中会被给定不同的权重值，例如![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0mx1tRu3xtCpENuP8yOPc1ocY2G3qHUpKSwfibnWbqosoPhqBQlFpw6g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的权重wdeltat=1，![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0VZw2PKIWtFYiaOM7dbRgbBWcbzibx0iauI2592352XApUKpUicOQgicnwrA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)的权重wlength=10，adapter cost的权重wadapter=100，此外也指定每个核的最大存储容量限制为memlimit（核库中给出了内存memory的计算公式），最终要在满足某些物理设计要求的前提下，使得三个优化目标的加权和值尽可能小，即

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0ibibwEib9IXghaxhCMnz0wdnPyyxWrnPJOnoYE7dvPsQE20So7XmnsRWA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

s.t.    (1) 任意模块之间不能有重叠；

         (2) 所有模块须均被放置在芯片内部；

         (3) 每个模块的memory≤memlimit.

**3.3  解决方案**

平面布图规划是NP完全问题，其优化过程通常是在某种表示方法的基础上使用确定性算法或随机优化算法。目前常用的平面布图的表示方法如下表所示：NPE（Normalized Polish Expression）、序列对（Sequence Pair）、BSG（Bounded-Sliceline-Grid）、TCG（Transitive Closure Graph）、O-tree、B\*-tree等。  

表1  平面布图表示法对比

![Image](https://mmbiz.qpic.cn/mmbiz_png/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0DCN2NZLjObWwKhfG2CfMj7lfwoMecKotvs8ulokG9akH9ZY2OZbDWQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

对于软模块的布图规划问题，Kim提出构造法\[6\]的确定型算法，即对每个软模块预设几个备选高和宽，然后在优化过程中逐个确定每个模块的长和宽。在使用构造法对软模块调整的步骤中，Kim给出模块权重的定义，并对最大权重模块的每个备选高和宽使用快速模拟退火(Fast-SA)\[7\]对平面布图进行评估并得到相应的平面布图。每个软模块的备选高和宽越多，则可能获得更好的平面布图，但运算时间也会大大增加。

模拟退火法是常见的布图优化随机优化算法，该算法在贪婪算法的基础上增加随机的因素，以一定的概率接受一个劣解，避免陷入局部最优解。基于快速模拟退火，Chang提出用B∗-tree\[8\]来表示一个布图规划。除了布图和总线长目标，也将布图规划的长宽比添加到目标函数中，针对固定轮廓布图问题，提出了一种动态改变代价函数中权重的快速算法\[9\]，以实现轮廓约束条件下的线长优化。但是模拟退火算法本身是一种随机算法，运行两次可能产生不同的布图规划结果，其参数难以控制，不能保证一次就收敛到最优值，一般需要多次尝试才能获得，因此在时间上效率不高。

针对上述人工智能深度学习芯片布图规划问题，利用图和组合优化的工具作者及其研究团队提出了一种新的基于核图结构的更加快速、更加灵活、更加高效的图优化加速算法，并利用Python编程，对ISPD 2020提供的20个benchmark基准示例进行测试。测试结果表明新的方法能通过计算资源的合理分配对任一指定神经网络的计算起到显著的加速效果，从而达到良好的计算性能。测试结果展示了我们的算法在计算分配方案时具有良好的时间复杂度，平均测试一个benchmark的时间只要0.2秒，优于当前主流方法的平均时间51.6秒；算法所计算解的质量大都接近、达到或超出现存的已知工作方案，具体布图方案将在后继科研论文中加以详细介绍。

如今，人工智能芯片是实现算法的硬件基础，也是未来人工智能时代的战略制高点，而固化的硬件加速器无法很好地支持日新月异的深度学习算法，因此从硬件层面提升深度学习算力愈发关键。从全球芯片产业发展历程及未来研究趋势来看，当前人工智能芯片尚处于初级起步探索阶段，无论是对芯片的相关理论研究还是在产业化应用方面都存在着巨大的创新空间。

**参考文献**

\[1\] 斋藤康毅(作者), 陆宇杰(译者). 深度学习入门: 基于Python的理论与实现. 北京: 人民邮电出版社, 2018.

\[2\] 刘衡祁. AI芯片的发展及应用. 电子技术与软件工程, 2019(22):91-92.

\[3\] 尹首一, 郭珩, 魏少军. 人工智能芯片发展的现状及趋势. 科技导报, 2018, 36(17): 45-51.

\[4\] Michael James, Marvin Tom, Patrick Groeneveld, Vladimir Kibardin. ISPD2020 Physical Mapping of Neural Networks on a Wafer-Scale Deep Learning Accelerator. ACM International Symposium on Physical Design 2020: 145-149.

\[5\] Andrew B. Kahng, Jens Lienig, Igor L. Markov, Jin Hu. VLSI Physical Design: From Graph Partitioning to Timing Closure. Springer, 2011.

\[6\] Kim J G , Kim Y D . A linear programming-based algorithm for floorplanning in VLSI design. IEEE Transactions on Computer Aided Design of Integrated Circuits & Systems, 2003, 22(5): 584-592.

\[7\] Xiaoping Tang and D.F. Wong. FAST-SP: a fast algorithm for block placement based on sequence pair. Proceedings of the ASP-DAC 2001. Asia and South Pacific Design Automation Conference 2001 (Cat. No.01EX455). IEEE, 2001.

\[8\] Yun-Chih Chang, Yao-Wen Chang, Guang-Ming Wu, Shu-Wei Wu. B\*-Trees: A New Representation for Non-Slicing Floorplans. in Proc. ACM/IEEE Design Automation Conf., Los Angeles, CA, Jun. 2000, pp. 458–463.

\[9\] Tung-Chieh Chen, Yao-Wen Chang. Modern floorplanning based on B\*-tree and fast simulated annealing. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2006, 25(4): 637-650. 

供稿：南京师范大学、福州大学：张晓岩，郭龙坤，徐楚楚，孙龙

部分图片来源网络

排版：柚子美编五号（西安交通大学金融优化组Riely）

如需转载请联系公众号

![Image](https://mmbiz.qpic.cn/mmbiz_jpg/TsSmxk3UaDN85QPCenZ9GNUd3CGBeNF0TbpSVsclcJv8YSI2ZZNdianopbJjygbIMnZqE40P54Jknt47Xk2icnUA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)